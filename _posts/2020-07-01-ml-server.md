---
layout: post
mathjax: true
title:  "Création d'un serveur pour l'apprentissage machine"
date:   2020-07-01 09:00:00 +0200
categories:
  - machine learning server
---

![ml-server](/assets/images/ml-server.png)

Après avoir passé quelques heures sur l'installation d'un serveur IA en local, finalement couronnée de succès, je vous propose un petit article récapitulatif des étapes de la création d'un serveur dédié à l'apprentissage machine  
C'est ma première configuration matérielle, donc relativement légère. Il faut compter 1400€ à l'heure de l'écriture de ces lignes pour la réalisation d'un projet similaire.  
Le tuto commence une fois que la machine a été physiquement assemblée et que via le bios on voit les différents composants. Je ne donne pas le détail des raisons des différentes installations, je pense que ça parlera à toutes celles et ceux qui s'intéressent au domaine. Par contre je mets à chaque fois les liens vers les docs utilisées et l'ensemble des commandes systèmes à exécuter.  

Les chapitres de ce tuto:  
- Configuration matérielle
- Installation du serveur Ubuntu
- Carte graphique: pilote NVIDIA, Cuda, cuDNN
- Installation de la pile de logiciels
- Connexion à distance 
- Tests
  
Happy Hacking  

# Configuration matérielle
Processeur AMD Ryzen 7 2700X Wraith Prism Edition - 3,7/4,3 GHz  
Carte mère Gaming TUF B450 Plus Asus  
RAM T-FORCE Dark Za - 2 x 16 Go - DDR4 3200 MHz - Noir  
Alimentation CORSAIR HX750 750W - 80 Plus Platinum  
Disque dur Samsung 860 EVO 500 Go 2.5'' SATA III (6 Gb/s)  
Boîtier FRACTAL DESIGN Meshify C Blanc  
Carte graphique ASUS Geforce RTX 2070 - DUAL OC EVO V2 - 8 Go  

# Installation du serveur Ubuntu
20.04 LTS (Focal Fossa)  

Création d'un unbuntu server depuis MacOS  
Récupération de Ubuntu 20.04 LTS via BitTorrent  

[Création de la clé d'installation via Etcher](https://ubuntu.com/tutorials/tutorial-create-a-usb-stick-on-macos#3-prepare-the-usb-stick)

[Installation du serveur](https://ubuntu.com/tutorials/tutorial-install-ubuntu-server#1-overview)  
màj à la version 20.06.1 pendant l'installation  

(X) Use an entire disk  
[X] Set up this disk as an LVM group  
  
partition 1: primary ESP, format fat32, mounted at /boot/efi 512M  
partition 2: format ext4, /boot 1G  
partition 3: PV of LVM volume group ubuntu-vg 464G  
  
nom: USER  
nom machine: ML-SERVER  
nom utilisateur: USER  
mdp: PASSWORD  
  
Installation d'un serveur SSH pour l'accès distant  
[X] Install OpenSSH server  
  
Featured Server Snaps: aucune installation particulière  
[]  
  
Installation de l'interface graphique  
[Install Full Gnome Desktop on Ubuntu 20.04 LTS Focal Fossa](https://linuxconfig.org/how-to-install-gnome-on-ubuntu-20-04-lts-focal-fossa)  
`sudo apt install tasksel`  
`sudo tasksel install ubuntu-desktop`  
`sudo reboot`  
  
màj de l'heure  
màj du système via Software Updater  



# Carte graphique: pilote NVIDIA, Cuda, cuDNN

Installation du pilote NVIDIA pour la carte graphique  

[How to install the NVIDIA drivers on Ubuntu](https://linuxconfig.org/how-to-install-the-nvidia-drivers-on-ubuntu-19-10-eoan-ermine-linux)  
`ubuntu-drivers devices`  
`sudo ubuntu-drivers autoinstall`  
`sudo reboot`  

L'option de l'installation via l'application Softwate & Updates ne fonctionne pas directement chez moi.  
Simplement cocher l'option dans Additional Drivers  
[X] Using NVIDIA driver metapackage from nvidia-driver-440 (proprietary, tested)  
Problème: pk-client-error-quark cannot download packages while offline (257)  

Cuda et cuDNN:  
[Installation CUDA 10.1](https://askubuntu.com/questions/1230645/when-is-cuda-gonna-be-released-for-ubuntu-20-04)   
`sudo apt install nvidia-cuda-toolkit`  
  
Vérification version de cuda:  
`nvcc -V`  

[Installation cuDNN (7.6.5)](https://developer.nvidia.com/rdp/form/cudnn-download-survey)  
Necessite un compte developpeur (gratuit) chez NVidia  
Download cuDNN v7.6.5 (November 5th, 2019), for CUDA 10.1  
cuDNN Library for Linux: cudnn-10.1-linux-x64-v7.6.5.32  

Se placer dans le répertoire où l'extraction a été faite:  
`sudo cp cuda/lib64/libcudnn* /usr/lib/cuda/lib64/`  
`sudo chmod a+r /usr/lib/cuda/include/cudnn.h /usr/lib/cuda/lib64/libcudnn*`  
`echo 'export LD_LIBRARY_PATH=/usr/lib/cuda/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc`  
`echo 'export LD_LIBRARY_PATH=/usr/lib/cuda/include:$LD_LIBRARY_PATH' >> ~/.bashrc`  
`source ~/.bashrc `  


# Installation de la pile de logiciels

Installation miniconda  
[Récupération de l'installateur](https://docs.conda.io/en/latest/miniconda.html#linux-installers)  
Miniconda3 Linux 64-bit  
  
`bash Miniconda3-latest-Linux-x86_64.sh`  
  
`conda update conda`  


Création d'un [environnement conda](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#creating-an-environment-from-an-environment-yml-file) minimal dédié à tensorflow avec JupyterLab  
créer le fichier tensorflow.yml  
`nano tensorflow.yml`  
avec pour [contenu](https://github.com/neodelphis/ml-server/blob/master/tensorflow.yml)  
```
name: tensorflow

dependencies:
    - python=3.7
    - pip>=19.0
    - tensorflow
    - tensorflow-gpu
    - scikit-learn
    - scipy
    - pandas
    - matplotlib
    - pillow
    - jupyterlab
```
  
`conda env create -f tensorflow.yml`  


Test que tensorflow voit le GPU  
`conda activate tensorflow`  
`python`  
`>>> import tensorflow as tf`  
`>>> tf.config.list_physical_devices('GPU')`  
doit afficher le GPU  
`>>> exit()`  
  
Ajout d'un kernel dans jupyter pour pouvoir utiliser le nouvel environnement sous JupyterLab  
  
Using Virtual Environments in Jupyter Notebook and Python: [Add Virtual Environment to Jupyter Notebook](https://janakiev.com/blog/jupyter-virtual-envs/)  
  
`pip install --user ipykernel`  
`python -m ipykernel install --user --name=tensorflow`  
  
Test:  
`jupyter lab`  
Dans les notebooks proposés on doit voir Python 3 et tensorflow  



# Connexion à distance 
Connexion à distance au serveur sur le réseau local depuis un mac  
  
Vérification du bon fonctionnement du serveur ssh  
`sudo service ssh status`  

Récupération de l'adresse ip du serveur  
`ip addr show`  

Depuis le termimal du client (mac)  
Remplacer USER@REMOTE.HOST avec utilisateur serveur et IP  
`ssh USER@REMOTE.HOST`  
  
Activation de l'environnement tensorflow  
`conda activate tensorflow`  
`jupyter lab`  
  
Connection à Jupyter lab via un [tunnel ssh](https://linuxize.com/post/how-to-setup-ssh-tunneling/)  
permet de rerouter le localhost du client sur le serveur distant  
`ssh -L localhost:8888:localhost:8888 -N -f USER@REMOTE.HOST`  
  
Dans firefox du client:  
`http://localhost:8888/lab`  


Utilisation du gpu dans un notebook  
[tensorflow & GPU](https://www.tensorflow.org/guide/gpu)  
Ajout du code suivant pour éviter le message d'erreur UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize  
```python3
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
  try:
    # Currently, memory growth needs to be the same across GPUs
    for gpu in gpus:
      tf.config.experimental.set_memory_growth(gpu, True)
    logical_gpus = tf.config.experimental.list_logical_devices('GPU')
    print(len(gpus), "Physical GPUs,", len(logical_gpus), "Logical GPUs")
  except RuntimeError as e:
    # Memory growth must be set before GPUs have been initialized
    print(e)
```

# Tests

[Notebook pour tester la configuration](https://github.com/neodelphis/ml-server/blob/master/test-gpu.ipynb)  
  
[Version avec les résultats d'exécution](https://github.com/neodelphis/ml-server/blob/master/test-gpu-x.ipynb)  
  
61 s pour la phase d'apprentissage au lieu de 1148 s sur le mac  

Enjoy :)

# References

- [The $1700 great Deep Learning box: Assembly, setup and benchmarks](https://blog.slavv.com/the-1700-great-deep-learning-box-assembly-setup-and-benchmarks-148c5ebe6415)
- [A definitive guide for Setting up a Deep Learning Workstation with Ubuntu 18.04](https://towardsdatascience.com/a-definitive-guide-for-setting-up-a-deep-learning-workstation-with-ubuntu-18-04-5459d70e19c3)
